{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import product, combinations\n",
    "from sklearn.preprocessing import normalize\n",
    "import settings\n",
    "import json\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from tags import NounTags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('data/coco_noun.tags'))\n",
    "nlp = spacy.load(settings.SPACY_MODEL)\n",
    "nounExtractor = NounTags(nlp, alpha=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Hypernomin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hyper(word1, word2):\n",
    "    sysn1 = wn.synsets(word1)\n",
    "    sysn2 = wn.synsets(word2)\n",
    "    res = False\n",
    "    for sys1, sys2 in product(sysn1, sysn2):\n",
    "        if (sys2 in sys1.common_hypernyms(sys2)) or (sys1 in sys2.common_hypernyms(sys1)):\n",
    "            res = True\n",
    "            break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hyper(words):\n",
    "    \"\"\"\n",
    "    Check if one word ins hyperomin of the other.\n",
    "\n",
    "    Args:\n",
    "        words (list): a list of words to be checked\n",
    "\n",
    "    Return:\n",
    "        bool\n",
    "    \"\"\"\n",
    "    check = True\n",
    "    for word1, word2 in combinations(words, 2):\n",
    "        sysn1 = wn.synsets(word1)\n",
    "        sysn2 = wn.synsets(word2)\n",
    "        check_hyp = False\n",
    "        for sys1, sys2 in product(sysn1, sysn2):\n",
    "            if (sys2 in sys1.common_hypernyms(sys2)) or \\\n",
    "               (sys1 in sys2.common_hypernyms(sys1)):\n",
    "                check_hyp = True\n",
    "                break\n",
    "        if not check_hyp:\n",
    "            check = False\n",
    "            break\n",
    "    return check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A baseball player prepares to swing at the ball. ',\n",
       " 'A ball player prepares to swing as the umpire and catcher look on.',\n",
       " 'Two baseball players and an umpire during a game.',\n",
       " 'A baseball player getting ready to swing at the ball. ',\n",
       " 'A baseball game is being played with the batter up.']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = '263823'\n",
    "caption_list = data['train2014'][id_]['captions']\n",
    "captions = [nlp(c) for c in caption_list]\n",
    "caption_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ball', 'baseball', 'player', 'game', 'umpire', 'catcher', 'batter'],\n",
       " [3, 4, 4, 2, 2, 1, 1],\n",
       " [0.07142857142857142,\n",
       "  0.09090909090909091,\n",
       "  0.14285714285714285,\n",
       "  0.18181818181818182,\n",
       "  0.5,\n",
       "  0.7142857142857143,\n",
       "  0.7272727272727273])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags, counts, rlocs = nounExtractor.preprocess(caption_list)\n",
    "tags, counts, rlocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### token dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a token dict indexed by lemma and POS tag (for noun and verbs)\n",
    "token_dict = defaultdict(set)\n",
    "for sent in captions:\n",
    "    for token in sent:\n",
    "        if token.pos_ in ['NOUN', 'VERB']:\n",
    "            token_dict[token.lemma_, token.pos_].add(token)\n",
    "token_dict = dict(token_dict)\n",
    "\n",
    "# keep only repeated tokens\n",
    "for k in list(token_dict):\n",
    "    if len(token_dict[k]) == 1:\n",
    "        del token_dict[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('ball', 'NOUN'): {ball, ball, ball},\n",
       " ('baseball', 'NOUN'): {baseball, baseball, baseball, baseball},\n",
       " ('be', 'VERB'): {is, being},\n",
       " ('game', 'NOUN'): {game, game},\n",
       " ('player', 'NOUN'): {player, player, player, players},\n",
       " ('prepare', 'VERB'): {prepares, prepares},\n",
       " ('swing', 'VERB'): {swing, swing, swing},\n",
       " ('umpire', 'NOUN'): {umpire, umpire}}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### children token dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build children token dict indexed by syntactic function\n",
    "child_dict = defaultdict(set)\n",
    "for k, tokens in token_dict.items():\n",
    "    for token in tokens:\n",
    "        for ctoken in token.children:\n",
    "            if ctoken.pos_ in ['NOUN', 'VERB']:\n",
    "                child_dict[k, ctoken.dep_].add(ctoken)\n",
    "child_dict = dict(child_dict)\n",
    "\n",
    "# keep only repeated children\n",
    "for k in list(child_dict):\n",
    "    if len(child_dict[k]) == 1:\n",
    "        del child_dict[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(('player', 'NOUN'), 'compound'): {ball, baseball, baseball, baseball},\n",
       " (('prepare', 'VERB'), 'nsubj'): {player, player},\n",
       " (('prepare', 'VERB'), 'xcomp'): {swing, swing}}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "child_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merged tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge tags keeping the highest scored\n",
    "remove_idxs = set()\n",
    "for tokens in child_dict.values():\n",
    "    idxs = sorted(set(tags.index(t.lemma_) for t in tokens if t.lemma_ in tags))\n",
    "    tags_to_check = [tags[i] for i in idxs]\n",
    "    if len(idxs) > 1:\n",
    "        check = check_hyper(tags_to_check)\n",
    "#         check = True\n",
    "#         for w0, w1 in combinations(tags_to_check, 2):\n",
    "#             if not check_hyper(w0, w1):\n",
    "#                 check = False\n",
    "#                 break\n",
    "        if check:\n",
    "            idxs = sorted(idxs)\n",
    "            remove_idxs.update(idxs[1:])\n",
    "            for id_ in idxs[1:]:\n",
    "                counts[idxs[0]] += counts[id_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tags = [t for i, t in enumerate(tags) if i not in remove_idxs]\n",
    "new_rlocs = [r for i, r in enumerate(rlocs) if i not in remove_idxs]\n",
    "new_counts = [c for i, c in enumerate(counts) if i not in remove_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1}, ['ball', 'baseball', 'player', 'game', 'umpire', 'catcher', 'batter'])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_idxs, tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ball', 'player', 'game', 'umpire', 'catcher', 'batter']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
