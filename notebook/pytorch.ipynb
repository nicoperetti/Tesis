{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import splitext, join, exists\n",
    "import json\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filename):\n",
    "    return sio.loadmat(filename, appendmat=False, squeeze_me=True)['data']\n",
    "\n",
    "def normalize_rows(mat, ord=2):\n",
    "    ''' return a row normalized matrix\n",
    "    '''\n",
    "    assert mat.ndim == 2\n",
    "    norms = zeros_to_eps(np.linalg.norm(mat, ord=ord, axis=1))\n",
    "    return mat / norms.reshape(-1, 1)\n",
    "\n",
    "def zeros_to_eps(mat):\n",
    "    ''' replace zeros in a matrix by a tiny constant\n",
    "    '''\n",
    "    mat[np.isclose(mat, 0.)] = np.finfo(mat.dtype).eps\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = json.load(open(\"../data/coco_noun.tags\", 'r'))\n",
    "vecs = json.load(open(\"../data/coco_noun.word2vec\", 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_dim = -1\n",
    "for w, vec in vecs.items():\n",
    "    if vec is not None:\n",
    "        vec_dim = len(vec)\n",
    "        break\n",
    "if vec_dim is None:\n",
    "    raise RuntimeError(\"couln'\\t set embeddings dimensionality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO_train2014_000000111189.dat\n"
     ]
    }
   ],
   "source": [
    "X, Y = {}, {}\n",
    "for set_ in [k for k in anno.keys() if k != \"tags\"]:\n",
    "    for i, imid in enumerate(imid_list):\n",
    "        # set image features\n",
    "        #fname = splitext(anno[set_][imid][\"file_name\"])[0] + \".dat\"\n",
    "        if fname in os.listdir(\"../data/\" + set_):\n",
    "            print(fname)\n",
    "            break\n",
    "            x = load(join(\"../data/\", set_, fname))\n",
    "            if i == 0:\n",
    "                n_samples = len(imid_list)\n",
    "                n_dim = len(x)\n",
    "                X[set_] = np.empty((n_samples, n_dim), dtype=np.float32)\n",
    "            X[set_][i] = normalize_rows(x.reshape(1, -1)).squeeze()\n",
    "\n",
    "            # set word embeddings (OOV tags are set to the zero vector)\n",
    "            tags = anno[set_][imid][\"tags\"]\n",
    "            y = [[0]*vec_dim if vecs[w] is None else vecs[w] for w in tags]\n",
    "            Y[set_][i] = normalize_rows(np.array(y, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load(join(\"../data/\", \"train2014\", \"COCO_train2014_000000111189.dat\"))\n",
    "x = normalize_rows(x.reshape(1, -1)).squeeze()\n",
    "n_dim = len(x)\n",
    "tags = anno[\"train2014\"][\"111189\"][\"tags\"]\n",
    "y = [[0]*vec_dim if vecs[w] is None else vecs[w] for w in tags]\n",
    "y = normalize_rows(np.array(y, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4096,), 11, (300,))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, len(y), y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(x)\n",
    "Y_train = [torch.from_numpy(elem) for elem in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4096]), 11, torch.Size([300]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.size(), len(Y_train), Y_train[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 300)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_X, dim_Y = X_train.shape[0], Y_train[0].shape[0]\n",
    "dim_X, dim_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bilineal\n",
    "class Bilinear(nn.Module):\n",
    "    def __init__(self, in1_features, in2_features, bias=True):\n",
    "        super().__init__()\n",
    "        self.bilin = nn.modules.Bilinear(in1_features, in2_features, out_features=1, bias=bias)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return [self.bilin(X, y) for y in Y]\n",
    "\n",
    "    def project_x(self, X):\n",
    "        if X.ndimension() == 1:\n",
    "            X = X.unsqueeze(0)\n",
    "        assert self.bilin.weight.size()[0] == 1\n",
    "        return torch.mm(X, self.bilin.weight[0])\n",
    "\n",
    "    def project_y(self, Y):\n",
    "        if Y.ndimension() == 1:\n",
    "            Y = Y.unsqueeze(0)\n",
    "        assert self.bilin.weight.size()[0] == 1\n",
    "        return torch.mm(Y, self.bilin.weight[0].transpose(1, 0))\n",
    "\n",
    "\n",
    "class ModelEbay(nn.Module):\n",
    "    def __init__(self, in1_features, in2_features, bias=True):\n",
    "        super().__init__()\n",
    "        self.fc1_1 = nn.Linear(in1_features, in2_features)\n",
    "        self.fc1_2 = nn.Linear(in2_features, in2_features)\n",
    "        self.fc2 = nn.Linear(2 * in2_features, in2_features)\n",
    "        self.fc3 = nn.Linear(in2_features, 1)\n",
    "\n",
    "    def forward_m(self, x, y):\n",
    "        x = F.tanh(self.fc1_1(x))\n",
    "        y = F.tanh(self.fc1_2(y))\n",
    "        ccat = F.tanh(torch.cat((x,y), dim=0))\n",
    "        hidden_l = F.tanh(self.fc2(ccat))\n",
    "        final = self.fc3(hidden_l)\n",
    "        return final\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return [self.forward_m(X, y) for y in Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Bilinear(in1_features=dim_X, in2_features=dim_Y, bias=True)\n",
    "model_ebay = ModelEbay(in1_features=dim_X, in2_features=dim_Y, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Variable(X_train)  #[Variable(x.unsqueeze_(0)) for x in X]\n",
    "Y = [Variable(y) for y in Y_train]\n",
    "out = model(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nico/.virtualenvs/tesis/lib/python3.5/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([-0.0186], grad_fn=<ThAddBackward>),\n",
       " tensor([-0.0200], grad_fn=<ThAddBackward>),\n",
       " tensor([-0.0254], grad_fn=<ThAddBackward>),\n",
       " tensor([-0.0182], grad_fn=<ThAddBackward>),\n",
       " tensor([-0.0133], grad_fn=<ThAddBackward>),\n",
       " tensor([-0.0172], grad_fn=<ThAddBackward>),\n",
       " tensor([-0.0225], grad_fn=<ThAddBackward>),\n",
       " tensor([-0.0251], grad_fn=<ThAddBackward>),\n",
       " tensor([-0.0152], grad_fn=<ThAddBackward>),\n",
       " tensor([-0.0172], grad_fn=<ThAddBackward>),\n",
       " tensor([-0.0164], grad_fn=<ThAddBackward>)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ebay(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
